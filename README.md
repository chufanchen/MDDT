# Learning to Modulate pre-trained Models in RL 
Thomas Schmied <sup>**1**</sup>, Markus Hofmarcher <sup>**1**</sup>, Fabian Paischer<sup>**1**</sup>, Razvan Pacscanu<sup>**2**</sup>, Sepp Hochreiter<sup>**1,3**</sup> 

<sup>**1**</sup>ELLIS Unit Linz and LIT AI Lab, Institute for Machine Learning, Johannes Kepler University Linz, Austria\
<sup>**2**</sup>DeepMind\
<sup>**3**</sup>Institute of Advanced Research in Artificial Intelligence (IARAI), Vienna, Austria

:warning: **UNDER CONSTRUCTION** :warning:

This repository will contain the source code and link to the generated datasets for our paper **"Learning to Modulate pre-trained Models in RL"** accepted at the [Reincarnating RL Workshop](https://reincarnating-rl.github.io/) at ICLR 2023. The paper is available [here](https://openreview.net/forum?id=Us6BtPZGei3). 


## Approach
![Learning-to-Modulate](./img/l2m.png)

## Accessing the Data
TBD

## Installation
TBD

## Running experiments
TBD

## Citation
Workshop paper: 
```
@inproceedings{schmied2023learning,
  title={Learning to Modulate pre-trained Models in RL},
  author={Schmied, Thomas and Hofmarcher, Markus and Paischer, Fabian and Pascanu, Razvan and Hochreiter, Sepp},
  booktitle={Workshop on Reincarnating Reinforcement Learning at ICLR}
  year={2023},
  url={https://openreview.net/forum?id=Us6BtPZGei3}
}
```


